# -*- coding: utf-8 -*-
"""diffusion-model-with-metrics.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PU0rgu-iRCj8ZQiVbSWnjh9u-BLvK4kU

The module jupytext is used to treat this .py file as a jupyter notebook file. To keep the output after every session, go to "File" -> "Jupytext" -> "Pair Notebook with ipynb document". This generates a file PY_FILENAME.ipynb.

# Imports
"""

import numpy as np
import matplotlib.pyplot as plt
from torchvision import datasets, transforms
import torch
import torch.nn as nn
import math
import os
from PIL import Image
import torchvision.transforms as T

if torch.cuda.is_available():
    print("Using GPU.")
    device = "cuda"
else:
    print("Using CPU.")
    device = "cpu"

"""# Definitions and Parameters"""

batch_size = 64
Timesteps = 300
beta0, betaT = 1e-4, 2e-2

betas = torch.linspace(beta0, betaT, Timesteps)
alphas = 1. - betas
alphas_cumprod = torch.cumprod(alphas, axis=0)
alphas_cumprod_prev = nn.functional.pad(alphas_cumprod[:-1], (1, 0), value=1.0)
sqrt_recip_alphas = torch.sqrt(1.0 / alphas)
sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)
sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - alphas_cumprod)
posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)

"""# Load MNIST Dataset"""

folder_path = "./data/mnist"

train_dataset = datasets.MNIST(root=folder_path, train=True, transform=transforms.ToTensor(), download=True)
test_dataset = datasets.MNIST(root=folder_path, train=False, transform=transforms.ToTensor(), download=True)

dataloader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=False)
test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)

"""# Data Exploration"""

train_image_data = train_dataset.data.numpy()
train_labels = train_dataset.targets.numpy()

assert (train_image_data.shape == np.array([60000, 28, 28])).all()
assert (train_labels.shape == np.array([60000,])).all()

def plot_images(images):
    """Plots the first 9 images."""
    amount_images_to_show = 9
    grid_shape = np.array([3, 3])
    for image_index in range(amount_images_to_show):
        plt.subplot(grid_shape[0], grid_shape[1], image_index + 1)
        plt.xticks([])
        plt.yticks([])
        image_to_show = images[image_index]
        plt.imshow(image_to_show, cmap="gray")
    plt.show()

plot_images(train_image_data)

"""# Forward Noise Process"""

def get_index_from_list(vals, t, x_shape):
    """ 
    gets vals[t] for a batch of indices
    """
    batch_size = t.shape[0]
    out = vals.gather(-1, t.cpu())
    return out.reshape(batch_size, *((1,) * (len(x_shape) - 1))).to(t.device)

def add_noise(image, t):
    noise = torch.randn_like(image)
    sqrt_alphas_cumprod_t = get_index_from_list(sqrt_alphas_cumprod, t, image.shape)
    sqrt_one_minus_alphas_cumprod_t = get_index_from_list(
        sqrt_one_minus_alphas_cumprod, t, image.shape)
    return sqrt_alphas_cumprod_t.to(device) * image.to(device) \
    + sqrt_one_minus_alphas_cumprod_t.to(device) * noise.to(device), noise.to(device)

"""variances = torch.ones(100).to(device) * 0.125
image = train_dataset.data[0].to(device)
noisy_images = torch.zeros([9, image.shape[0], image.shape[1]])
for i in range(9):
    index_stepsize = variances.shape[0] / 8
    noisy_image = add_noise(image, variances[:int(i * index_stepsize) + 1])
    noisy_images[i] = noisy_image
plot_images(noisy_images)

# Noise Prediction Model Implementation
"""

class Block(nn.Module):
    def __init__(self, in_ch, out_ch, time_emb_dim, up=False):
        super().__init__()
        self.time_mlp =  nn.Linear(time_emb_dim, out_ch)
        if up:
            self.conv1 = nn.Conv2d(2*in_ch, out_ch, 3, padding=1)
            self.transform = nn.ConvTranspose2d(out_ch, out_ch, 4, 2, 1)
        else:
            self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1)
            self.transform = nn.Conv2d(out_ch, out_ch, 4, 2, 1)
        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1)
        self.bnorm1 = nn.BatchNorm2d(out_ch)
        self.bnorm2 = nn.BatchNorm2d(out_ch)
        self.relu  = nn.ReLU()
        
    def forward(self, x, t, ):
        # First Conv
        h = self.bnorm1(self.relu(self.conv1(x)))
        # Time embedding
        time_emb = self.relu(self.time_mlp(t))
        # Extend last 2 dimensions
        time_emb = time_emb[(..., ) + (None, ) * 2]
        # Add time channel
        h = h + time_emb
        # Second Conv
        h = self.bnorm2(self.relu(self.conv2(h)))
        # Down or Upsample
        return self.transform(h)


class SinusoidalPositionEmbeddings(nn.Module):
    def __init__(self, dim):
        super().__init__()
        self.dim = dim

    def forward(self, time):
        device = time.device
        half_dim = self.dim // 2
        embeddings = math.log(10000) / (half_dim - 1)
        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)
        embeddings = time[:, None] * embeddings[None, :]
        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)
        return embeddings


class SimpleUnet(nn.Module):
    def __init__(self):
        super().__init__()
        image_channels = 3
        down_channels = (64, 128, 256)
        up_channels = (256, 128, 64)
        out_dim = 1 
        time_emb_dim = 32

        # Time embedding
        self.time_mlp = nn.Sequential(
                SinusoidalPositionEmbeddings(time_emb_dim),
                nn.Linear(time_emb_dim, time_emb_dim),
                nn.ReLU()
            )
        
        self.conv0 = nn.Conv2d(image_channels, down_channels[0], 3, padding=1)

        self.downs = nn.ModuleList([Block(down_channels[i], down_channels[i+1], \
                                    time_emb_dim) \
                    for i in range(len(down_channels)-1)])
        self.ups = nn.ModuleList([Block(up_channels[i], up_channels[i+1], \
                                        time_emb_dim, up=True) \
                    for i in range(len(up_channels)-1)])

        self.output = nn.Conv2d(up_channels[-1], 1, out_dim)

    def forward(self, x, timestep):
        t = self.time_mlp(timestep)
        x = self.conv0(x)
        residual_inputs = []
        for down in self.downs:
            x = down(x, t)
            residual_inputs.append(x)
        for up in self.ups:
            residual_x = residual_inputs.pop()
            x = torch.cat((x, residual_x), dim=1)           
            x = up(x, t)
        return self.output(x)

model = SimpleUnet()
print("Num params: ", sum(p.numel() for p in model.parameters()))

"""# Loss function"""

def get_loss(model, x_0, t):
    x_noisy, noise = add_noise(x_0, t)
    noise_pred = model(x_noisy, t)
    return nn.functional.l1_loss(noise, noise_pred)

"""# Sampling"""

def denoising_process(images, beta, noise_predictor, simple_variance=False):
    "sample image"
    
    images_size = images.shape
    timesteps = beta.shape[0] - 1
    alpha = 1 - beta
    alpha_cum = torch.cumprod(alpha, dim=0).to(device)
    if simple_variance:
        variances = beta
    else:
        alpha_cum_t_minus_1 = torch.cat([torch.Tensor([0]).to(device), alpha_cum[:-1]], axis=0).to(device)
        variances = (1-alpha_cum_t_minus_1)/(1-alpha_cum) 
        variances = variances * beta
    
    variances = variances.to(device)
    x_t = images.to(device)
    
    with torch.no_grad():
        for timestep in range(timesteps, 0, -1):
            timestep = torch.tensor(timestep, dtype=torch.int8)
            predicted_noise = noise_predictor(x_t, timestep).to(device)
            z = torch.normal(torch.zeros(images_size), torch.ones(images_size))

            if timestep == 1:
                z = torch.zeros(images_size)

            z = z.to(device)
            x_t = (variances[timestep] * z + (x_t - (1-alpha[timestep])/torch.sqrt(1-alpha_cum[timestep])*predicted_noise) \
            / torch.sqrt(alpha[timestep])).to(device)
    return x_t

"""sample_images_size = [100, 1, 28, 28]
sample_images = torch.ones(sample_images_size).to(device)
beta = torch.ones(100).to(device)
samples = denoising_process(sample_images, beta, model).to(device)

assert samples.shape == sample_images.shape

plt.subplot(1,2,1)
plt.imshow(samples[0][0], cmap="gray")
plt.subplot(1,2,2)
plt.imshow(samples[1][0], cmap="gray")
plt.show()

# Training

from torch.optim import Adam

model.to(device)
optimizer = Adam(model.parameters(), lr=0.001)
epochs = 3
loss_history = []

for epoch in range(epochs):
    for step, batch in enumerate(dataloader):
      optimizer.zero_grad()

      if batch[0].shape[0] != batch_size: break
      t = torch.randint(0, T, (batch_size,), device=device).long()
      loss = get_loss(model, batch[0], t)
      loss.backward()
      optimizer.step()
      loss_history.append(loss.item())

    print(f"Epoch {epoch} | Loss: {loss.item()} ")
    

plt.plot(loss_history)

#Evaluation
"""

!pip install pytorch-ignite

from ignite.engine import Engine, Events
from ignite.metrics import InceptionScore, FID

def fid_with_noise_level(batch, noise_level):
  def process_function_fid(engine, data_batch):
      if len(data_batch.shape) == 3: data_batch = data_batch[None,:,:,:]
      noisy_images = data_batch + torch.rand(data_batch.shape) * noise_level
      return noisy_images, data_batch

  engine_fid = Engine(process_function_fid)
  fid_scores = []

  fid = FID()
  fid.attach(engine_fid, "fid")

  @engine_fid.on(Events.EPOCH_COMPLETED)
  def on_epoch_completed(engine):
      metrics = engine.state.metrics
      
      fid_score = metrics["fid"]
      fid_scores.append(fid_score)

  results = engine_fid.run(batch, max_epochs=5)

  return fid_scores

def is_with_noise_level(batch, noise_level):
  def process_function_is(engine, data_batch):
      if len(data_batch.shape) == 3: data_batch = data_batch[None,:,:,:]
      return data_batch

  engine_is = Engine(process_function_is)
  is_scores = []

  inception_score = InceptionScore()
  inception_score.attach(engine_is, "is")

  @engine_is.on(Events.EPOCH_COMPLETED)
  def on_epoch_completed(engine):
      metrics = engine.state.metrics

      is_score = metrics["is"]
      is_scores.append(is_score)

  results = engine_is.run(batch, max_epochs=5)

  return is_scores

def metrics_with_noise_levels(batch, noise_levels):
  # give images 3 channels if they only have 1:  
  if len(batch.shape) == 4 and batch.shape[1] == 1:
    batch_shape = batch.shape
    batch_three_channels = torch.zeros(batch_shape[0], 3, batch_shape[2], batch_shape[3])

    batch_three_channels[:,0,:,:] = evaluation_batch[:,0,:,:]
    batch_three_channels[:,1,:,:] = evaluation_batch[:,0,:,:]
    batch_three_channels[:,2,:,:] = evaluation_batch[:,0,:,:]

    batch = torch.FloatTensor(batch_three_channels)

  # Resize images to 299x299
  transform = T.Resize(size = (299,299))
  batch = transform(batch)

  for noise in noise_levels:
    fid_scores = fid_with_noise_level(batch, noise)
    is_scores = is_with_noise_level(batch, noise)

    print(f"Noise: {noise}")
    print(f"   FID: {np.mean(fid_scores):.3e} +- {np.std(fid_scores):.3e}")
    print(f"   IS:  {np.mean(is_scores):.3e}  +- {np.std(is_scores):.3e}")

noises = [0.001, 0.1]
evaluation_batch, _ = next(iter(dataloader))

metrics_with_noise_levels(evaluation_batch, noises)